{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select a branch for trial run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.edges\n",
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.nodes\n",
      "         term  size                                              genes  \\\n",
      "0  Cluster0-0  5254  STRN SMG9 LRRC15 INTS14 PTGR3 DBT CLINT1 ACBD6...   \n",
      "1  Cluster1-0  3052  RAB29 INPP5F ARL6IP6 CALM1 OLFM4 ACSL3 NTN1 LY...   \n",
      "2  Cluster1-1  1891  ACSL3 NTN1 SLC4A2 TMEM51 SYTL3 CNST CLTCL1 DAZ...   \n",
      "3  Cluster2-0  1061  UBR3 TONSL TOP3B GFPT1 TFIP11 TDRD3 ZNF672 UBE...   \n",
      "4  Cluster2-1   921  PAAF1 PSMD14 PSMA1 GINS3 MIDN ERH WDR59 DPYSL4...   \n",
      "\n",
      "   stability  \n",
      "0         93  \n",
      "1         22  \n",
      "2         32  \n",
      "3         37  \n",
      "4         24          parent       child     type\n",
      "0  Cluster0-0  Cluster1-0  default\n",
      "1  Cluster0-0  Cluster1-1  default\n",
      "2  Cluster0-0  Cluster1-2  default\n",
      "3  Cluster0-0  Cluster1-3  default\n",
      "4  Cluster0-0  Cluster1-4  default\n",
      "Number of descendants for Cluster1-2: 16\n",
      "(17, 4) (16, 3)\n"
     ]
    }
   ],
   "source": [
    "## Pick an example lineage to test the loop\n",
    "\n",
    "# lineage = 'Cluster2-7' #spliceosomal complex\n",
    "lineage = 'Cluster1-2' #mitochondrial\n",
    "# lineage = 'Cluster2-0' #endomembrane system\n",
    "# edge file \n",
    "import os\n",
    "from model_nodes_edges import load_nodes_edges\n",
    "from file_io import get_model_directory_path\n",
    "from ontology_modify import get_descendants\n",
    "import pandas as pd\n",
    "os.environ['MODEL_ANNOTATION_ROOT'] = 'Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/'\n",
    " \n",
    "model_name = \"MuSIC2_Maps\"\n",
    "version = \"May2023_final\"\n",
    "file_name = \"muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned\"\n",
    "\n",
    "nodes, edges = load_nodes_edges(model_name, version, file_name)\n",
    "print(nodes.head(), edges.head())\n",
    "\n",
    "descendants = get_descendants(lineage, edges)\n",
    "print(f\"Number of descendants for {lineage}: {len(descendants)}\")\n",
    "\n",
    "# get the sub edge and sub node table with this lineage \n",
    "subbranch = [lineage] + descendants\n",
    "sub_edges = edges.loc[edges['parent'].isin(subbranch) & edges['child'].isin(subbranch)]\n",
    "sub_edges.to_csv(os.path.join(get_model_directory_path(model_name, version), f'{file_name}.branch1-2.edges'), sep = '\\t', index=False, header=False)\n",
    "sub_nodes = nodes.loc[nodes['term'].isin(subbranch)]\n",
    "sub_nodes.to_csv(os.path.join(get_model_directory_path(model_name, version), f'{file_name}.branch1-2.nodes'), sep = '\\t', index=False, header=False)\n",
    "print(sub_nodes.shape, sub_edges.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create root node info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.edges\n",
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.nodes\n",
      "         term  size                                              genes  \\\n",
      "0  Cluster0-0  5254  STRN SMG9 LRRC15 INTS14 PTGR3 DBT CLINT1 ACBD6...   \n",
      "1  Cluster1-0  3052  RAB29 INPP5F ARL6IP6 CALM1 OLFM4 ACSL3 NTN1 LY...   \n",
      "2  Cluster1-1  1891  ACSL3 NTN1 SLC4A2 TMEM51 SYTL3 CNST CLTCL1 DAZ...   \n",
      "3  Cluster2-0  1061  UBR3 TONSL TOP3B GFPT1 TFIP11 TDRD3 ZNF672 UBE...   \n",
      "4  Cluster2-1   921  PAAF1 PSMD14 PSMA1 GINS3 MIDN ERH WDR59 DPYSL4...   \n",
      "\n",
      "   stability  \n",
      "0         93  \n",
      "1         22  \n",
      "2         32  \n",
      "3         37  \n",
      "4         24          parent       child     type\n",
      "0  Cluster0-0  Cluster1-0  default\n",
      "1  Cluster0-0  Cluster1-1  default\n",
      "2  Cluster0-0  Cluster1-2  default\n",
      "3  Cluster0-0  Cluster1-3  default\n",
      "4  Cluster0-0  Cluster1-4  default\n"
     ]
    }
   ],
   "source": [
    "from query_mygene import get_mygene_for_system\n",
    "from file_io import write_system_json, get_root_path\n",
    "import os\n",
    "from model_nodes_edges import load_nodes_edges\n",
    "\n",
    "os.environ['MODEL_ANNOTATION_ROOT'] = 'Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/'\n",
    " \n",
    "model_name = \"MuSIC2_Maps\"\n",
    "version = \"May2023_final\"\n",
    "file_name = \"muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned\"\n",
    "\n",
    "nodes, edges = load_nodes_edges(model_name, version, file_name)\n",
    "# print(nodes.head(), edges.head())\n",
    "\n",
    "root_node= nodes[nodes['term'] == 'Cluster0-0']\n",
    "root_genes = root_node['genes'].values[0].split(' ') # total 5254 genes\n",
    "\n",
    "mygene_res = get_mygene_for_system(root_genes)\n",
    "\n",
    "write_system_json(mygene_res, model_name, version, 'root_node', 'my_gene', get_root_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mygene_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the code to move the analysis page md file to the git repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.edges\n",
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.nodes\n",
      "Cluster1-0 does not have analysis page\n",
      "Cluster1-1 does not have analysis page\n",
      "Cluster3-19 does not have analysis page\n",
      "Cluster2-26 does not have analysis page\n",
      "Cluster3-30 does not have analysis page\n",
      "Cluster2-41 does not have analysis page\n",
      "Cluster2-55 does not have analysis page\n",
      "Cluster1-21 does not have analysis page\n",
      "Cluster1-23 does not have analysis page\n",
      "Cluster2-57 does not have analysis page\n",
      "Cluster4-42 does not have analysis page\n",
      "Cluster2-80 does not have analysis page\n",
      "Cluster2-74 does not have analysis page\n"
     ]
    }
   ],
   "source": [
    "#check the number of analysis_pages in the directory \n",
    "import os\n",
    "from model_nodes_edges import load_nodes_edges\n",
    "from file_io import get_model_directory_path\n",
    "\n",
    "os.environ['MODEL_ANNOTATION_ROOT'] = 'Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/'\n",
    " \n",
    "model_name = \"MuSIC2_Maps\"\n",
    "version = \"May2023_final\"\n",
    "file_name = \"muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned\"\n",
    "\n",
    "nodes, edges = load_nodes_edges(model_name, version, file_name)\n",
    "node_names = nodes['term'].values.tolist()\n",
    "node_names.remove('Cluster0-0') \n",
    "# print(len(node_names))\n",
    "git_repo_dir = \"/cellar/users/mhu/src/MUSIC2_systems/May2023_final\"\n",
    "num_analysispg = []\n",
    "for node in node_names:\n",
    "    analysis_page = os.path.join(get_model_directory_path(model_name, version), node, f\"{node}_analysis_page.md\")\n",
    "    if os.path.exists(analysis_page):\n",
    "        num_analysispg.append(node)\n",
    "    else:\n",
    "        print(node + \" does not have analysis page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis page for Cluster1-0 does not exist\n",
      "Analysis page for Cluster1-1 does not exist\n"
     ]
    }
   ],
   "source": [
    "git_repo_dir = \"/cellar/users/mhu/src/MUSIC2_systems/May2023_final\"\n",
    "for node in node_names:\n",
    "    analysis_page = os.path.join(get_model_directory_path(model_name, version), node, f\"{node}_analysis_page.md\")\n",
    "    # print(analysis_page)\n",
    "    if not os.path.exists(analysis_page):\n",
    "        print(f\"Analysis page for {node} does not exist\")\n",
    "    \n",
    "    # check if the file already in repo\n",
    "    if not os.path.exists(f'{git_repo_dir}/{node}_analysis_page.md'): \n",
    "        # copy this page to the MuSIC2 systems git repo dir\n",
    "        os.system(f\"cp {analysis_page} {git_repo_dir}\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://github.com/idekerlab/MUSIC2_systems/blob/main/May2023_final/Cluster2-0_analysis_page.md',\n",
       " 'https://github.com/idekerlab/MUSIC2_systems/blob/main/May2023_final/Cluster2-1_analysis_page.md',\n",
       " 'https://github.com/idekerlab/MUSIC2_systems/blob/main/May2023_final/Cluster2-2_analysis_page.md',\n",
       " 'https://github.com/idekerlab/MUSIC2_systems/blob/main/May2023_final/Cluster2-3_analysis_page.md']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "for node in node_names:\n",
    "    if os.path.exists(f'{git_repo_dir}/{node}_analysis_page.md'): \n",
    "        link  = f'https://github.com/idekerlab/MUSIC2_systems/blob/main/May2023_final/{node}_analysis_page.md'\n",
    "        urls.append(link)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cluster2-0', 'Cluster2-1', 'Cluster2-2', 'Cluster2-3', 'Cluster2-4', 'Cluster1-2', 'Cluster3-0', 'Cluster3-1']\n"
     ]
    }
   ],
   "source": [
    "biggest_node = nodes.loc[(nodes['size']> 400) & (nodes['size']<1500), 'term'].values.tolist()\n",
    "\n",
    "print(biggest_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.expand.branch4-1.edges\n",
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.expand.branch4-1.nodes\n",
      "Estimated number of tokens: 1744\n",
      "running Chatgpt for Cluster6-1\n",
      "2681\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai_query import openai_chat\n",
    "from topological_sorting import generate_graph, topological_sort\n",
    "from model_nodes_edges import load_nodes_edges, get_genes\n",
    "from file_io import read_system_json, get_root_path, get_model_directory_path, write_system_tsv, read_system_tsv\n",
    "from gene_feature import summarize_gene_feature, summarized_gene_feature_to_tsv\n",
    "from pages import  write_system_page_txt, read_system_page_txt, write_system_page,create_music_2_system_analysis_page, parse_gpt4_response\n",
    "from chatgpt_prompts import create_music_2_chatGPT_prompt_text, create_system_prompt_page, create_chatGPT_prompt_parent, concat_children_summary, estimate_tokens\n",
    "from ontology_modify import find_children\n",
    "\n",
    "## load the config file \n",
    "####remember to change config if you want to use different map/model\n",
    "with open('config.json') as config_file:\n",
    "    data = json.load(config_file)\n",
    "\n",
    "#`MODEL_ANNOTATION_ROOT` is the path to the root directory of the model annotation repository\n",
    "os.environ['MODEL_ANNOTATION_ROOT'] = data[\"MODEL_ANNOTATION_ROOT\"]\n",
    "\n",
    "# load the API key\n",
    "key = data[\"OPENAI_API_KEY\"] \n",
    "temperature = data[\"TEMP\"] # Set your temperature here \n",
    "# CH: I want it to be deterministic, so I set temperature to 0\n",
    "max_tokens = data[\"MAX_TOKENS\"] # Set your max tokens here\n",
    "rate_per_token = data[\"RATE_PER_TOKEN\"]# Set your rate per token here \n",
    "model = data[\"GPT_MODEL\"]\n",
    "DOLLAR_LIMIT = data[\"DOLLAR_LIMIT\"]  # Set your dollar limit here\n",
    "logfile_name = data[\"LOG_NAME\"] # Set your log file name here\n",
    "# set the context for music2\n",
    "context = data[\"MUSIC2_CONTEXT\"]\n",
    "\n",
    "# set the model name and version, canbe found in the directory\n",
    "model_name = data[\"MAP_NAME\"]\n",
    "\n",
    "version = data[\"MAP_V\"]\n",
    "\n",
    "file_name = data[\"MAP_FILE\"]\n",
    "\n",
    "## remember to change the name of the log file \n",
    "LOG_FILE = os.path.join(get_model_directory_path(model_name, version), f'{logfile_name}log.json')\n",
    "\n",
    "## load the model \n",
    "nodes, edges = load_nodes_edges(model_name, version, file_name)\n",
    "# print(nodes.head()), print(edges.head())\n",
    "\n",
    "# get the root node info\n",
    "root_node_info = read_system_json(model_name, version, 'root_node', 'my_gene', get_root_path())\n",
    "## get the sorted nodes \n",
    "graph = generate_graph(edges)\n",
    "sorted_nodes = topological_sort(graph)\n",
    "\n",
    "huge_token_nodes = []\n",
    "system = 'Cluster6-1'\n",
    "genes = get_genes(system, nodes)\n",
    "if len(genes) < 120:\n",
    "    # generate the prompt with gene features\n",
    "    # TODO: modify the gene feature to remove duplicates #check if the length can shorten \n",
    "    summarized_info = summarize_gene_feature(root_node_info, genes)  # Summarize the gene features\n",
    "    summarized_tsv = summarized_gene_feature_to_tsv(summarized_info) \n",
    "    write_system_tsv(summarized_tsv, model_name, version, system, 'go_summary', get_root_path())\n",
    "    prompt = create_music_2_chatGPT_prompt_text(system,nodes, summarized_tsv, n_genes=max(2, int(len(genes)/25)))\n",
    "\n",
    "    est_tokens = estimate_tokens(context + '\\n' +prompt)\n",
    "\n",
    "    print (f\"Estimated number of tokens: {est_tokens}\")\n",
    "    if est_tokens > 5500:\n",
    "        huge_token_nodes.append(system)\n",
    "    write_system_page_txt(prompt, model_name, version, system, \"chatgpt_prompt\", get_root_path()) # write the prompt to text file\n",
    "    \n",
    "\n",
    "    response_path = os.path.join(get_model_directory_path(model_name, version), system, f\"{system}_chatgpt_response\")\n",
    "\n",
    "    # run chatgpt if response file does not exist, avoid duplicate runs\n",
    "    if not os.path.exists(response_path + '.html'):\n",
    "        print(f\"running Chatgpt for {system}\")\n",
    "        # TODO: run chatgpt\n",
    "        prompt = read_system_page_txt(model_name, version, system, \"chatgpt_prompt\", get_root_path())\n",
    "        # print(prompt)\n",
    "        response_text = openai_chat(context, prompt, model,temperature, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "        if response_text:\n",
    "            #save a html file\n",
    "            with open(response_path + '.html', \"w\") as f:\n",
    "                title, summary, ref = parse_gpt4_response(response_text)\n",
    "                chatgpt_res = f\"<h2>{system} GPT response</h2><h3>{title}</h3><h4>Summary</h4><div>{summary}</div><h4>Reference</h4><div>{ref}</div>\"\n",
    "                f.write(f\"<!DOCTYPE html>\\n<html>\\n{chatgpt_res}\\n</html>\")\n",
    "            #save to the analysis page\n",
    "            if not summarized_tsv:\n",
    "                summarized_tsv = read_system_tsv(model_name, version, system, \"go_summary\", get_root_path())\n",
    "                \n",
    "            analysis_page = create_music_2_system_analysis_page(system, response_text, nodes, summarized_tsv, n_genes=max(2, int(len(genes)/25)))\n",
    "            write_system_page(analysis_page, model_name, version, system, \"analysis_page\", get_root_path()) # write an analysis page in html format\n",
    "\n",
    "    else:\n",
    "        print(f\"Chatgpt response file exists for {system}, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.edges\n",
      "/cellar/users/mhu/Projects/cellmaps_annotate_hierarchy/cellmaps_annotate_hierarchy/MuSIC2_Maps/May2023_final/muse_imgdim_1024_ppidim_1024_latentd_128_layered.chi_10.maxres_80.alg_leiden.pruned.nodes\n",
      "running Chatgpt for Cluster2-2\n",
      "5074\n",
      "running Chatgpt for Cluster2-3\n",
      "3792\n",
      "running Chatgpt for Cluster2-4\n",
      "3367\n",
      "running Chatgpt for Cluster1-2\n",
      "3412\n",
      "running Chatgpt for Cluster3-0\n",
      "3680\n",
      "running Chatgpt for Cluster3-1\n",
      "2811\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai_query import openai_chat\n",
    "from topological_sorting import generate_graph, topological_sort\n",
    "from model_nodes_edges import load_nodes_edges, get_genes\n",
    "from file_io import read_system_json, get_root_path, get_model_directory_path, write_system_tsv, read_system_tsv\n",
    "from gene_feature import summarize_gene_feature, summarized_gene_feature_to_tsv\n",
    "from pages_io import write_system_page, read_system_page, create_music_2_system_analysis_page\n",
    "from chatgpt_prompts import create_music_2_chatGPT_prompt_text, create_music_2_chatGPT_prompt_parent,  estimate_tokens\n",
    "from ontology_modify import find_children\n",
    "\n",
    "## load the config file \n",
    "####remember to change config if you want to use different map/model\n",
    "with open('config.json') as config_file:\n",
    "    data = json.load(config_file)\n",
    "\n",
    "#`MODEL_ANNOTATION_ROOT` is the path to the root directory of the model annotation repository\n",
    "os.environ['MODEL_ANNOTATION_ROOT'] = data[\"MODEL_ANNOTATION_ROOT\"]\n",
    "\n",
    "# load the API key\n",
    "key = data[\"OPENAI_API_KEY\"] \n",
    "temperature = data[\"TEMP\"] # Set your temperature here \n",
    "# CH: I want it to be deterministic, so I set temperature to 0\n",
    "max_tokens = data[\"MAX_TOKENS\"] # Set your max tokens here\n",
    "rate_per_token = data[\"RATE_PER_TOKEN\"]# Set your rate per token here \n",
    "model = data[\"GPT_MODEL\"]\n",
    "DOLLAR_LIMIT = data[\"DOLLAR_LIMIT\"]  # Set your dollar limit here\n",
    "logfile_name = data[\"LOG_NAME\"] # Set your log file name here\n",
    "# set the context for music2\n",
    "context = data[\"MUSIC2_CONTEXT\"]\n",
    "\n",
    "# set the model name and version, canbe found in the directory\n",
    "model_name = data[\"MAP_NAME\"]\n",
    "\n",
    "version = data[\"MAP_V\"]\n",
    "\n",
    "file_name = data[\"MAP_FILE\"]\n",
    "\n",
    "## remember to change the name of the log file \n",
    "LOG_FILE = os.path.join(get_model_directory_path(model_name, version), f'{logfile_name}log.json')\n",
    "\n",
    "## load the model \n",
    "nodes, edges = load_nodes_edges(model_name, version, file_name)\n",
    "# print(nodes.head()), print(edges.head())\n",
    "\n",
    "# get the root node info\n",
    "root_node_info = read_system_json(model_name, version, 'root_node', 'my_gene', get_root_path())\n",
    "## get the sorted nodes \n",
    "graph = generate_graph(edges)\n",
    "sorted_nodes = topological_sort(graph)\n",
    "\n",
    "huge_token_nodes = []\n",
    "system = 'Cluster2-5'\n",
    "for system in biggest_node:\n",
    "    genes = get_genes(system, nodes)\n",
    "    prompt = read_system_page('txt', model_name, version, system, \"chatgpt_prompt\", get_root_path())\n",
    "    # print(prompt)\n",
    "    response_path = os.path.join(get_model_directory_path(model_name, version), system, f\"{system}_chatgpt_response_temp0\")\n",
    "    if not os.path.exists(response_path + '.md'):\n",
    "        print(f\"running Chatgpt for {system}\")\n",
    "        # TODO: run chatgpt\n",
    "        prompt = read_system_page('txt', model_name, version, system, \"chatgpt_prompt\", get_root_path())\n",
    "        # print(prompt)\n",
    "\n",
    "        ### set temperature to 0\n",
    "        response_text = openai_chat(context, prompt, model,0, max_tokens, rate_per_token, LOG_FILE, DOLLAR_LIMIT)\n",
    "        if response_text:\n",
    "            # save markdown file\n",
    "            with open(response_path + '.md', 'w') as f:\n",
    "                f.write(response_text)\n",
    "\n",
    "        # #keep getting gene features \n",
    "        # summarized_info = summarize_gene_feature(root_node_info, genes)  # Summarize the gene features\n",
    "        # summarized_tsv = summarized_gene_feature_to_tsv(summarized_info) \n",
    "        # write_system_tsv(summarized_tsv, model_name, version, system, 'go_summary', get_root_path())\n",
    "        # analysis_page = create_music_2_system_analysis_page(system, response_text, nodes, summarized_tsv, n_genes=max(2, int(len(genes)/25)))\n",
    "        # write_system_page(analysis_page,'md',model_name, version, system, \"analysis_page\", get_root_path()) # write an analysis page in markdown format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
