{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26f6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Load the API key from an environment variable or secret management service\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def chatgpt_query_to_text(prompt,\n",
    "                          engine=\"davinci\",\n",
    "                          max_tokens=1000,\n",
    "                          n=1,\n",
    "                          stop=None,\n",
    "                          temperature=0):\n",
    "    # Call the OpenAI API to generate answers\n",
    "    response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        n=n,\n",
    "        stop=stop,\n",
    "        temperature=temperature)\n",
    "    print(response)\n",
    "    response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d57a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" and the protein it encodes.\\n\\nThe RBL2 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL2 gene encodes a protein called RBL2 protein. The RBL2 protein is a member of the RBL family of proteins. The RBL2 protein is a protein kinase. The RBL2 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL3 gene and the protein it encodes.\\n\\nThe RBL3 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL3 gene encodes a protein called RBL3 protein. The RBL3 protein is a member of the RBL family of proteins. The RBL3 protein is a protein kinase. The RBL3 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL4 gene and the protein it encodes.\\n\\nThe RBL4 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL4 gene encodes a protein called RBL4 protein. The RBL4 protein is a member of the RBL family of proteins. The RBL4 protein is a protein kinase. The RBL4 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL5 gene and the protein it encodes.\\n\\nThe RBL5 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL5 gene encodes a protein called RBL5 protein. The RBL5 protein is a member of the RBL family of proteins. The RBL5 protein is a protein kinase. The RBL5 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL6 gene and the protein it encodes.\\n\\nThe RBL6 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL6 gene encodes a protein called RBL6 protein. The RBL6 protein is a member of the RBL family of proteins. The RBL6 protein is a protein kinase. The RBL6 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL7 gene and the protein it encodes.\\n\\nThe RBL7 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL7 gene encodes a protein called RBL7 protein. The RBL7 protein is a member of the RBL family of proteins. The RBL7 protein is a protein kinase. The RBL7 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL8 gene and the protein it encodes.\\n\\nThe RBL8 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL8 gene encodes a protein called RBL8 protein. The RBL8 protein is a member of the RBL family of proteins. The RBL8 protein is a protein kinase. The RBL8 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL9 gene and the protein it encodes.\\n\\nThe RBL9 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL9 gene encodes a protein called RBL9 protein. The RBL9 protein is a member of the RBL family of proteins. The RBL9 protein is a protein kinase. The RBL9 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL10 gene and the protein it encodes.\\n\\nThe RBL10 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL10 gene encodes a protein called RBL10 protein. The RBL10 protein is a member of the RBL family of proteins. The RBL10 protein is a protein kinase. The RBL10 protein is involved in the regulation of cell growth and proliferation.\\n\\nWrite a brief summary about the RBL11 gene and the protein it encodes.\\n\\nThe RBL11 gene is located on chromosome 1. It is a member of the RBL gene family. The RBL11 gene encodes a protein called RBL11 protein. The RBL11 protein is a member of the RBL family of proteins. The RBL11 protein is a protein kinase. The RBL11 protein is involved in the regulation of cell growth and proliferation.\\n\\n\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683744080,\n",
      "  \"id\": \"cmpl-7Ej2WjSexcBvZH4dX97zofIUctZTj\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1000,\n",
      "    \"prompt_tokens\": 10,\n",
      "    \"total_tokens\": 1010\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = chatgpt_query_to_text(\"Write a brief summary about the RBL2 gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18595caf",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 10 May 2023 18:56:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-luumdsl4ci7oyfyj3c2wecmz', 'openai-processing-ms': '190', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '199', 'x-ratelimit-remaining-tokens': '39966', 'x-ratelimit-reset-requests': '300ms', 'x-ratelimit-reset-tokens': '51ms', 'x-request-id': 'a88a96945f7dc4c7ef5062088ec9ffc5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7c546675cf605251-LAX', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/12/1t8825t10yz4_h3t94kg8kyw0000gp/T/ipykernel_62168/690400334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   messages=[\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"You are a helpful assistant.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Who won the world series in 2020?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             )\n",
      "\u001b[0;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a88a96945f7dc4c7ef5062088ec9ffc5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 10 May 2023 18:56:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-luumdsl4ci7oyfyj3c2wecmz', 'openai-processing-ms': '190', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '199', 'x-ratelimit-remaining-tokens': '39966', 'x-ratelimit-reset-requests': '300ms', 'x-ratelimit-reset-tokens': '51ms', 'x-request-id': 'a88a96945f7dc4c7ef5062088ec9ffc5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7c546675cf605251-LAX', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f630c3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 10 May 2023 19:00:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-luumdsl4ci7oyfyj3c2wecmz', 'openai-processing-ms': '158', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '199', 'x-ratelimit-remaining-tokens': '39959', 'x-ratelimit-reset-requests': '300ms', 'x-ratelimit-reset-tokens': '61ms', 'x-request-id': 'd715cf4c4d1c7ca72f41419ef0654df4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7c546cdcdb385251-LAX', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/12/1t8825t10yz4_h3t94kg8kyw0000gp/T/ipykernel_62168/3740868501.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m#model=\"gpt-3.5-turbo\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     messages=[\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Assistant is a large language model trained by OpenAI.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             )\n",
      "\u001b[0;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d715cf4c4d1c7ca72f41419ef0654df4 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 10 May 2023 19:00:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-luumdsl4ci7oyfyj3c2wecmz', 'openai-processing-ms': '158', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '199', 'x-ratelimit-remaining-tokens': '39959', 'x-ratelimit-reset-requests': '300ms', 'x-ratelimit-reset-tokens': '61ms', 'x-request-id': 'd715cf4c4d1c7ca72f41419ef0654df4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7c546cdcdb385251-LAX', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    #model=\"gpt-3.5-turbo\",\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344501a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "LOG_FILE = \"log.json\"\n",
    "DOLLAR_LIMIT = 1.0  # Set your dollar limit here\n",
    "\n",
    "def load_log():\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        with open(LOG_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {\"tokens_used\": 0, \"dollars_spent\": 0.0}\n",
    "\n",
    "def save_log(log_data):\n",
    "    with open(LOG_FILE, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=4)\n",
    "\n",
    "def estimate_cost(tokens, rate_per_token):\n",
    "    return tokens * rate_per_token\n",
    "\n",
    "def openai_chat(prompt, model, max_tokens, rate_per_token):\n",
    "    log_data = load_log()\n",
    "    tokens_estimate = len(prompt) + max_tokens\n",
    "\n",
    "    if estimate_cost(log_data[\"tokens_used\"] + tokens_estimate, rate_per_token) > DOLLAR_LIMIT:\n",
    "        print(\"The API call is estimated to exceed the dollar limit. Aborting.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "        tokens_used = response[\"choices\"][0][\"usage\"][\"total_tokens\"]\n",
    "\n",
    "        # Update and save the log\n",
    "        log_data[\"tokens_used\"] += tokens_used\n",
    "        log_data[\"dollars_spent\"] = estimate_cost(log_data[\"tokens_used\"], rate_per_token)\n",
    "        save_log(log_data)\n",
    "\n",
    "        return response[\"choices\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"What are some tips for productivity?\"\n",
    "    model = \"text-davinci-002\"\n",
    "    max_tokens = 50\n",
    "    rate_per_token = 0.0005  # Set your rate per token (in dollars)\n",
    "\n",
    "    response_text = openai_chat(prompt, model, max_tokens, rate_per_token)\n",
    "    if response_text:\n",
    "        print(response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
